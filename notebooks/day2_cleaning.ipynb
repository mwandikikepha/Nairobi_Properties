{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eccf9a52",
   "metadata": {},
   "source": [
    "Day2.ipynb - We already have 800+ rows. Cleaning this data into useful insights will happen here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "087704d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f9c05d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting rows: 2511\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/home/kepha/nairobi_property/data/raw_listings.csv\")\n",
    "df_clean = df.copy()\n",
    "print(f\"Starting rows: {len(df_clean)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0872cfb",
   "metadata": {},
   "source": [
    "REMOVING DUPLICATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e860ec6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates before: 1612\n"
     ]
    }
   ],
   "source": [
    "print(f\"Duplicates before: {df_clean.duplicated().sum()}\")\n",
    "df_clean = df_clean.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b5865e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after removing duplicates: 899\n",
      "Duplicates after: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Rows after removing duplicates: {len(df_clean)}\")\n",
    "print(f\"Duplicates after: {df_clean.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715905c5",
   "metadata": {},
   "source": [
    "REMOVING PRICE OUTLIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f58a00b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After price filtering, 1M-500M: 890 rows remain\n"
     ]
    }
   ],
   "source": [
    "df_clean = df_clean[(df_clean['price_kes'] >= 1_000_000) & \n",
    "                    (df_clean['price_kes'] <= 500_000_000)]\n",
    "print(f\"After price filtering, 1M-500M: {len(df_clean)} rows remain\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c0303e",
   "metadata": {},
   "source": [
    "SORTING SIZE OUTLIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "110c7be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count       799.000000\n",
      "mean       2172.765144\n",
      "std        5192.789039\n",
      "min          10.760000\n",
      "25%         764.240000\n",
      "50%        1259.390000\n",
      "75%        2174.330000\n",
      "max      107640.000000\n",
      "Name: size_sqft, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df_clean['size_sqft'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47997a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           location  bedrooms  size_sqft  price_kes\n",
      "176        Kilimani         4     129.17   25000000\n",
      "199       Westlands         2      96.88   14000000\n",
      "234   Spring Valley         3      43.06   23100000\n",
      "332        Kitisuru         4      32.29   60000000\n",
      "339        Kitisuru         5      53.82   85000000\n",
      "349     Kiambu Road         7      75.35   85000000\n",
      "361       Westlands         2      96.88   14000000\n",
      "364        Kilimani         4     129.17   25000000\n",
      "446           Karen         5      75.35  170000000\n",
      "458           Karen         4      53.82  105000000\n",
      "481           Runda         4      53.82  120000000\n",
      "483           Nyari         8      86.11  180000000\n",
      "581       Westlands         3      21.53   28000000\n",
      "588        Kitisuru         5      86.11  350000000\n",
      "601         Loresho         4      43.06   75000000\n",
      "650      Kileleshwa         2      96.88   90000000\n",
      "733           Runda         5      64.58  350000000\n",
      "763           Kyuna         4      32.29   48000000\n",
      "768         Loresho         4      64.58  120000000\n",
      "831           Kyuna         5      64.58  130000000\n",
      "941           Kyuna         5      64.58  131000000\n",
      "958        Muthaiga         6      75.35  180000000\n",
      "979           Runda         5      75.35  260000000\n",
      "1089      Lavington         5      64.58  155000000\n",
      "1103        Loresho         4      64.58  120000000\n",
      "1296          Runda         5      75.35  260000000\n",
      "1379          Runda         4     139.93   35000000\n",
      "1615          Karen         5      75.35  170000000\n",
      "1680      Riverside         2      10.76   12500000\n",
      "1727       Syokimau         4      10.76   13900000\n",
      "1778     Kileleshwa         3      32.29   18000000\n"
     ]
    }
   ],
   "source": [
    "# Identifying suspiciously small sizes, under 200 sqft but the price is over 10M KES\n",
    "suspicious_small = (df_clean['size_sqft'] < 200) & (df_clean['price_kes'] > 10000000)\n",
    "print(df_clean.loc[suspicious_small, ['location', 'bedrooms', 'size_sqft', 'price_kes']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6b042ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           location  bedrooms  size_sqft  price_kes\n",
      "176        Kilimani         4     1291.7   25000000\n",
      "199       Westlands         2      968.8   14000000\n",
      "234   Spring Valley         3      430.6   23100000\n",
      "332        Kitisuru         4      322.9   60000000\n",
      "339        Kitisuru         5      538.2   85000000\n",
      "349     Kiambu Road         7      753.5   85000000\n",
      "361       Westlands         2      968.8   14000000\n",
      "364        Kilimani         4     1291.7   25000000\n",
      "446           Karen         5      753.5  170000000\n",
      "458           Karen         4      538.2  105000000\n",
      "481           Runda         4      538.2  120000000\n",
      "483           Nyari         8      861.1  180000000\n",
      "581       Westlands         3      215.3   28000000\n",
      "588        Kitisuru         5      861.1  350000000\n",
      "601         Loresho         4      430.6   75000000\n",
      "650      Kileleshwa         2      968.8   90000000\n",
      "733           Runda         5      645.8  350000000\n",
      "763           Kyuna         4      322.9   48000000\n",
      "768         Loresho         4      645.8  120000000\n",
      "831           Kyuna         5      645.8  130000000\n",
      "941           Kyuna         5      645.8  131000000\n",
      "958        Muthaiga         6      753.5  180000000\n",
      "979           Runda         5      753.5  260000000\n",
      "1089      Lavington         5      645.8  155000000\n",
      "1103        Loresho         4      645.8  120000000\n",
      "1296          Runda         5      753.5  260000000\n",
      "1379          Runda         4     1399.3   35000000\n",
      "1615          Karen         5      753.5  170000000\n",
      "1680      Riverside         2      107.6   12500000\n",
      "1727       Syokimau         4      107.6   13900000\n",
      "1778     Kileleshwa         3      322.9   18000000\n"
     ]
    }
   ],
   "source": [
    "#Multiply the size by 10 for these suspicious entries, assuming a possible decimal point error\n",
    "df_clean.loc[suspicious_small, 'size_sqft'] = df_clean.loc[suspicious_small, 'size_sqft'] * 10\n",
    "print(df_clean.loc[suspicious_small, ['location', 'bedrooms', 'size_sqft', 'price_kes']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aeaacd3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       location  bedrooms  size_sqft  size_acres  price_kes\n",
      "993    Kilimani         3  107640.00    2.471074   24000000\n",
      "1806  Westlands         1   52722.07    1.210332    6200000\n",
      "1108      Karen        11   46511.24    1.067751  210000000\n",
      "1794      Runda         5   46511.24    1.067751   98000000\n",
      "333     Loresho         4   43099.06    0.989418   75000000\n"
     ]
    }
   ],
   "source": [
    "# Add acres column to understand scale\n",
    "df_clean['size_acres'] = df_clean['size_sqft'] / 43560\n",
    "\n",
    "large_properties = df_clean[df_clean['size_sqft'] > 20000][\n",
    "    ['location', 'bedrooms', 'size_sqft', 'size_acres', 'price_kes']\n",
    "].sort_values('size_sqft', ascending=False)\n",
    "\n",
    "print(large_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83f219bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have decided to remove the large properties that we multiplied by 10, as they are likely outliers and may skew the analysis. I will filter them out based on their size and price per sqft.\n",
    "large_properties = df_clean[df_clean['size_sqft'] > 20000]\n",
    "df_clean = df_clean[~df_clean.index.isin(large_properties.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d06e8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After size filtering (>200 sqft): 881 rows\n"
     ]
    }
   ],
   "source": [
    "df_clean = df_clean[(df_clean['size_sqft'] >= 200) | (df_clean['size_sqft'].isna())]\n",
    "print(f\"After size filtering (>200 sqft): {len(df_clean)} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44a2dcad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with missing sizes: 91\n"
     ]
    }
   ],
   "source": [
    "\n",
    "missing_sizes = df_clean['size_sqft'].isna().sum()\n",
    "print(f\"Rows with missing sizes: {missing_sizes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbaab7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping missing sizes: 790 rows\n"
     ]
    }
   ],
   "source": [
    "#DRopping rows with missing sizes for now, as we cannot impute them without more information\n",
    "df_clean = df_clean.dropna(subset=['size_sqft'])\n",
    "print(f\"After dropping missing sizes: {len(df_clean)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea036880",
   "metadata": {},
   "source": [
    "SORTING AMMENITIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c0f8bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping missing amenities: 759 rows\n"
     ]
    }
   ],
   "source": [
    "#dropping properties with no ammenities listed, as they are likely incomplete listings\n",
    "df_clean = df_clean.dropna(subset=['amenities'])\n",
    "print(f\"After dropping missing amenities: {len(df_clean)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd1f52d",
   "metadata": {},
   "source": [
    "FINALLY : STANDARDIZING THE TEXTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "332ff7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['location'] = df_clean['location'].str.title().str.strip()\n",
    "df_clean['property_type'] = df_clean['property_type'].str.title().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1325c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning complete, Kept 759 listings\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cleaning complete, Kept {len(df_clean)} listings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590eca92",
   "metadata": {},
   "source": [
    "FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e178db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: price_per_sqft\n"
     ]
    }
   ],
   "source": [
    "# Price per square foot\n",
    "df_clean['price_per_sqft'] = df_clean['price_kes'] / df_clean['size_sqft']\n",
    "print(\"Created: price_per_sqft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "424e42a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: amenity_score\n"
     ]
    }
   ],
   "source": [
    "#Creating amenity score\n",
    "#Counts amenities each property has by counting commas eg \"Parking, Pool, Gym\" has 2 commas = 3 amenities.\n",
    "\n",
    "def count_amenities(amenities_str):\n",
    "    if pd.isna(amenities_str) or amenities_str == 'None':\n",
    "        return 0\n",
    "    return amenities_str.count(',') + 1\n",
    "\n",
    "df_clean['amenity_score'] = df_clean['amenities'].apply(count_amenities)\n",
    "print(\"Created: amenity_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "259c24e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: month\n"
     ]
    }
   ],
   "source": [
    "# Month from listing date\n",
    "df_clean['listing_date'] = pd.to_datetime(df_clean['listing_date'])\n",
    "df_clean['month'] = df_clean['listing_date'].dt.month\n",
    "print(\"Created: month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7dd9c27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.drop(columns=['size_acres'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ae4db4",
   "metadata": {},
   "source": [
    "SAVE TO CLEAN_LISTINGS CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80d08250",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv(\"/home/kepha/nairobi_property/data/clean_listings.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mainenv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
